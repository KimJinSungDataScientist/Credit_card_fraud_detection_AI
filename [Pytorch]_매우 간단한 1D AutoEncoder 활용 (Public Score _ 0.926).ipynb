{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kimjinsung/anaconda3/envs/for_pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13862e3-bb27-47af-9b58-a9fbf804df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 400\n",
    "LR = 1e-2\n",
    "BS = 16384\n",
    "SEED = 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd",
   "metadata": {},
   "source": [
    "## 시드고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
   "metadata": {},
   "source": [
    "## 데이터로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "train_df = train_df.drop(columns=['ID'])\n",
    "val_df = pd.read_csv('./data/val.csv')\n",
    "val_df = val_df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20652bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kimjinsung/anaconda3/envs/for_pytorch/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py:86: UserWarning: Only one sample available. You may want to reshape your data array\n",
      "  warnings.warn(\n",
      "/home/kimjinsung/anaconda3/envs/for_pytorch/lib/python3.9/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-507.376637004058239 > -608.947611459223936). You may want to try with a higher value of support_fraction (current value: 0.001).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "val_normal, val_fraud = val_df['Class'].value_counts()\n",
    "val_contamination = val_fraud / val_normal\n",
    "\n",
    "cov = EllipticEnvelope(support_fraction = 0.001, contamination = val_contamination+0.0002,random_state=777)\n",
    "\n",
    "ee_pred = cov.fit_predict(train_df)\n",
    "ee_pred = list(map(lambda x : 0 if x==1 else 1, ee_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee3644ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Class'] = ee_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61cf732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['Class']==0].drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
   "metadata": {},
   "source": [
    "## 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, eval_mode):\n",
    "        self.df = df\n",
    "        self.eval_mode = eval_mode\n",
    "        if self.eval_mode:\n",
    "            self.labels = self.df['Class'].values\n",
    "            self.df = self.df.drop(columns=['Class']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.eval_mode:\n",
    "            self.x = self.df[index]\n",
    "            self.y = self.labels[index]\n",
    "            return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d880481-1965-499d-9caa-fdfa8526f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(df=train_df, eval_mode=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=24)\n",
    "\n",
    "val_dataset = MyDataset(df = val_df, eval_mode=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39962463-032f-490a-a76d-c03991795f38",
   "metadata": {},
   "source": [
    "## 1D AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3664c4d0-f1f2-4971-9090-4d6ee66309ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Linear(30,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.Linear(128,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64,30),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.Decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
   "metadata": {},
   "source": [
    "## Train (학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        # Loss Function\n",
    "        self.criterion = nn.L1Loss().to(self.device)\n",
    "        \n",
    "    def fit(self, ):\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        for epoch in range(EPOCHS):\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            for x in iter(self.train_loader):\n",
    "                x = x.float().to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                _x = self.model(x)\n",
    "                loss = self.criterion(x, _x)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            score = self.validation(self.model, 0.95)\n",
    "            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
    "\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(score)\n",
    "\n",
    "            if best_score < score:\n",
    "                best_score = score\n",
    "                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n",
    "    \n",
    "    def validation(self, eval_model, thr):\n",
    "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        eval_model.eval()\n",
    "        pred = []\n",
    "        true = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader):\n",
    "                x = x.float().to(self.device)\n",
    "\n",
    "                _x = self.model(x)\n",
    "                diff = cos(x, _x).cpu().tolist()\n",
    "                batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
    "                pred += batch_pred\n",
    "                true += y.tolist()\n",
    "\n",
    "        return f1_score(true, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86142d9a-68b7-4d04-8423-49d28025411d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [0] Train loss : [0.5478326422827584] Val Score : [0.0010881344945152598])\n",
      "Epoch : [1] Train loss : [0.36832513553755625] Val Score : [0.0854042301120617])\n",
      "Epoch : [2] Train loss : [0.27339077634470804] Val Score : [0.29533943393670514])\n",
      "Epoch : [3] Train loss : [0.2174246140888759] Val Score : [0.39661198085711613])\n",
      "Epoch : [4] Train loss : [0.18371987768581935] Val Score : [0.4461775679325306])\n",
      "Epoch : [5] Train loss : [0.1613823026418686] Val Score : [0.4679963481115707])\n",
      "Epoch : [6] Train loss : [0.14559366873332433] Val Score : [0.48495470474700497])\n",
      "Epoch : [7] Train loss : [0.133496527160917] Val Score : [0.4969888382359309])\n",
      "Epoch : [8] Train loss : [0.12487076329333442] Val Score : [0.5013320882783676])\n",
      "Epoch : [9] Train loss : [0.11769869604281016] Val Score : [0.5058766468706869])\n",
      "Epoch : [10] Train loss : [0.11093506749187197] Val Score : [0.5091224804176124])\n",
      "Epoch : [11] Train loss : [0.1057761013507843] Val Score : [0.5120467646372988])\n",
      "Epoch : [12] Train loss : [0.1016093481864248] Val Score : [0.5147973341565076])\n",
      "Epoch : [13] Train loss : [0.09888664207288198] Val Score : [0.5168843874195664])\n",
      "Epoch : [14] Train loss : [0.0969031953385898] Val Score : [0.5186844414718952])\n",
      "Epoch : [15] Train loss : [0.09456997258322579] Val Score : [0.5205133421516981])\n",
      "Epoch : [16] Train loss : [0.09200611816985267] Val Score : [0.5217603380943587])\n",
      "Epoch : [17] Train loss : [0.09072856179305486] Val Score : [0.5230322754335729])\n",
      "Epoch : [18] Train loss : [0.08802484720945358] Val Score : [0.5254002744367214])\n",
      "Epoch : [19] Train loss : [0.08571876479046685] Val Score : [0.5275886446169271])\n",
      "Epoch : [20] Train loss : [0.08401186125619071] Val Score : [0.5260054617776617])\n",
      "Epoch : [21] Train loss : [0.08168224671057292] Val Score : [0.5288190867947024])\n",
      "Epoch : [22] Train loss : [0.08254135719367436] Val Score : [0.5299939251334721])\n",
      "Epoch : [23] Train loss : [0.08073893934488297] Val Score : [0.5303575492794963])\n",
      "Epoch : [24] Train loss : [0.07922820001840591] Val Score : [0.5301750712820299])\n",
      "Epoch : [25] Train loss : [0.07976630117212023] Val Score : [0.5328593190650799])\n",
      "Epoch : [26] Train loss : [0.076855688222817] Val Score : [0.5327919770339831])\n",
      "Epoch : [27] Train loss : [0.07580360450914927] Val Score : [0.5344591518178194])\n",
      "Epoch : [28] Train loss : [0.07589306788785118] Val Score : [0.5356334465154309])\n",
      "Epoch : [29] Train loss : [0.07378238971744265] Val Score : [0.5363950248576622])\n",
      "Epoch : [30] Train loss : [0.07218553658042635] Val Score : [0.5367842009326989])\n",
      "Epoch : [31] Train loss : [0.07022313241447721] Val Score : [0.5384001968205163])\n",
      "Epoch : [32] Train loss : [0.06801066334758486] Val Score : [0.5408372899692211])\n",
      "Epoch : [33] Train loss : [0.06668006096567426] Val Score : [0.5408372899692211])\n",
      "Epoch : [34] Train loss : [0.06678013290677752] Val Score : [0.5422365635673053])\n",
      "Epoch : [35] Train loss : [0.06499580187456948] Val Score : [0.5427188253653])\n",
      "Epoch : [36] Train loss : [0.06359949654766492] Val Score : [0.5441140534215738])\n",
      "Epoch : [37] Train loss : [0.06320403516292572] Val Score : [0.5442163422725665])\n",
      "Epoch : [38] Train loss : [0.06289314212543624] Val Score : [0.5460123351765206])\n",
      "Epoch : [39] Train loss : [0.0639710005904947] Val Score : [0.5462310020573558])\n",
      "Epoch : [40] Train loss : [0.06277957877942494] Val Score : [0.545687326564355])\n",
      "Epoch : [41] Train loss : [0.06240897199937275] Val Score : [0.5488671189923648])\n",
      "Epoch : [42] Train loss : [0.06201143190264702] Val Score : [0.5479239703689552])\n",
      "Epoch : [43] Train loss : [0.0604715741106442] Val Score : [0.5478081016335639])\n",
      "Epoch : [44] Train loss : [0.058147956750222614] Val Score : [0.5492284130390661])\n",
      "Epoch : [45] Train loss : [0.058422352586473734] Val Score : [0.5494716466579079])\n",
      "Epoch : [46] Train loss : [0.05818963849118778] Val Score : [0.5499639140767333])\n",
      "Epoch : [47] Train loss : [0.057048674672842026] Val Score : [0.550088207505037])\n",
      "Epoch : [48] Train loss : [0.05665509455970356] Val Score : [0.5508445183715132])\n",
      "Epoch : [49] Train loss : [0.05618602942143168] Val Score : [0.5526829003362292])\n",
      "Epoch : [50] Train loss : [0.0557965130678245] Val Score : [0.5529543625269938])\n",
      "Epoch : [51] Train loss : [0.05305561955486025] Val Score : [0.5509723592989528])\n",
      "Epoch : [52] Train loss : [0.053414427276168554] Val Score : [0.5528183459663629])\n",
      "Epoch : [53] Train loss : [0.055919457759175985] Val Score : [0.5540635212673894])\n",
      "Epoch : [54] Train loss : [0.05386606763516154] Val Score : [0.5536431462307628])\n",
      "Epoch : [55] Train loss : [0.05316831011857305] Val Score : [0.5536431462307628])\n",
      "Epoch : [56] Train loss : [0.052429668073143275] Val Score : [0.5529543625269938])\n",
      "Epoch : [57] Train loss : [0.052669896078961234] Val Score : [0.5546325411730989])\n",
      "Epoch : [58] Train loss : [0.05209128398980413] Val Score : [0.554204854984325])\n",
      "Epoch : [59] Train loss : [0.052670350564377647] Val Score : [0.5555048866039274])\n",
      "Epoch : [60] Train loss : [0.05162377974816731] Val Score : [0.5556525296376691])\n",
      "Epoch : [61] Train loss : [0.05177465985928263] Val Score : [0.556552321072903])\n",
      "Epoch : [62] Train loss : [0.05089850351214409] Val Score : [0.5582667196871773])\n",
      "Epoch : [63] Train loss : [0.04747519535677774] Val Score : [0.5582667196871773])\n",
      "Epoch : [64] Train loss : [0.04872396375451769] Val Score : [0.5595695120153324])\n",
      "Epoch : [65] Train loss : [0.050185462726014] Val Score : [0.5579485464511985])\n",
      "Epoch : [66] Train loss : [0.050250787287950516] Val Score : [0.5634215972732056])\n",
      "Epoch : [67] Train loss : [0.0487247279712132] Val Score : [0.5634215972732056])\n",
      "Epoch : [68] Train loss : [0.04796296198453222] Val Score : [0.5639801983006851])\n",
      "Epoch : [69] Train loss : [0.047018833458423615] Val Score : [0.5645473990169181])\n",
      "Epoch : [70] Train loss : [0.04803399369120598] Val Score : [0.5698567937968483])\n",
      "Epoch : [71] Train loss : [0.047633886869464605] Val Score : [0.5716480581173843])\n",
      "Epoch : [72] Train loss : [0.048264063362564356] Val Score : [0.5808400645805448])\n",
      "Epoch : [73] Train loss : [0.04979406297206879] Val Score : [0.5872554904314667])\n",
      "Epoch : [74] Train loss : [0.04869385436177254] Val Score : [0.5966253027265187])\n",
      "Epoch : [75] Train loss : [0.04716898767011506] Val Score : [0.6131975743550268])\n",
      "Epoch : [76] Train loss : [0.04587751094784055] Val Score : [0.6614216855893797])\n",
      "Epoch : [77] Train loss : [0.04702362311737878] Val Score : [0.7059866032567539])\n",
      "Epoch : [78] Train loss : [0.044020200946501324] Val Score : [0.7267446884090669])\n",
      "Epoch : [79] Train loss : [0.04499471772994314] Val Score : [0.730971061881369])\n",
      "Epoch : [80] Train loss : [0.045336254473243444] Val Score : [0.7331432493795871])\n",
      "Epoch : [81] Train loss : [0.04518044260995729] Val Score : [0.7376112450647377])\n",
      "Epoch : [82] Train loss : [0.043807643332651684] Val Score : [0.7470759905302604])\n",
      "Epoch : [83] Train loss : [0.04443844088486263] Val Score : [0.7331432493795871])\n",
      "Epoch : [84] Train loss : [0.04503336495586804] Val Score : [0.7470759905302604])\n",
      "Epoch : [85] Train loss : [0.047126716801098416] Val Score : [0.7399094305905288])\n",
      "Epoch : [86] Train loss : [0.043853194053683965] Val Score : [0.7470759905302604])\n",
      "Epoch : [87] Train loss : [0.045046163988964896] Val Score : [0.7495600450513867])\n",
      "Epoch : [88] Train loss : [0.042685557156801224] Val Score : [0.7470759905302604])\n",
      "Epoch : [89] Train loss : [0.04429340522204127] Val Score : [0.7495600450513867])\n",
      "Epoch : [90] Train loss : [0.043717720678874424] Val Score : [0.762761970120889])\n",
      "Epoch : [91] Train loss : [0.04215562716126442] Val Score : [0.762761970120889])\n",
      "Epoch : [92] Train loss : [0.040697202618633] Val Score : [0.7655703273293624])\n",
      "Epoch : [93] Train loss : [0.04224151000380516] Val Score : [0.7573184229436457])\n",
      "Epoch : [94] Train loss : [0.04054695953215871] Val Score : [0.7573184229436457])\n",
      "Epoch : [95] Train loss : [0.040365947144372125] Val Score : [0.752094104263044])\n",
      "Epoch : [96] Train loss : [0.040549510823828835] Val Score : [0.752094104263044])\n",
      "Epoch : [97] Train loss : [0.041272612022502084] Val Score : [0.7495600450513867])\n",
      "Epoch : [98] Train loss : [0.041027212249381204] Val Score : [0.7495600450513867])\n",
      "Epoch : [99] Train loss : [0.039271501558167596] Val Score : [0.7495600450513867])\n",
      "Epoch : [100] Train loss : [0.03807739061968667] Val Score : [0.7495600450513867])\n",
      "Epoch : [101] Train loss : [0.037595713777201514] Val Score : [0.7495600450513867])\n",
      "Epoch : [102] Train loss : [0.03856210357376507] Val Score : [0.752094104263044])\n",
      "Epoch : [103] Train loss : [0.03821238981825965] Val Score : [0.752094104263044])\n",
      "Epoch 00104: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch : [104] Train loss : [0.03437865498874869] Val Score : [0.7600119366040216])\n",
      "Epoch : [105] Train loss : [0.0322588642260858] Val Score : [0.7600119366040216])\n",
      "Epoch : [106] Train loss : [0.031390798411199024] Val Score : [0.7684388896488608])\n",
      "Epoch : [107] Train loss : [0.03188262640365532] Val Score : [0.762761970120889])\n",
      "Epoch : [108] Train loss : [0.03296362688498838] Val Score : [0.752094104263044])\n",
      "Epoch : [109] Train loss : [0.03265862113663128] Val Score : [0.7573184229436457])\n",
      "Epoch : [110] Train loss : [0.03188089361148221] Val Score : [0.7600119366040216])\n",
      "Epoch : [111] Train loss : [0.030760067914213454] Val Score : [0.762761970120889])\n",
      "Epoch : [112] Train loss : [0.03030252962240151] Val Score : [0.762761970120889])\n",
      "Epoch : [113] Train loss : [0.03203780709632805] Val Score : [0.762761970120889])\n",
      "Epoch : [114] Train loss : [0.03241627264235701] Val Score : [0.762761970120889])\n",
      "Epoch : [115] Train loss : [0.03141948900052479] Val Score : [0.762761970120889])\n",
      "Epoch : [116] Train loss : [0.03235377185046673] Val Score : [0.762761970120889])\n",
      "Epoch : [117] Train loss : [0.030451766082218716] Val Score : [0.7573184229436457])\n",
      "Epoch 00118: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch : [118] Train loss : [0.02925073036125728] Val Score : [0.7573184229436457])\n",
      "Epoch : [119] Train loss : [0.028882720906819617] Val Score : [0.7655703273293624])\n",
      "Epoch : [120] Train loss : [0.026754548773169518] Val Score : [0.762761970120889])\n",
      "Epoch : [121] Train loss : [0.02631687213267599] Val Score : [0.7600119366040216])\n",
      "Epoch : [122] Train loss : [0.026757425761648586] Val Score : [0.762761970120889])\n",
      "Epoch : [123] Train loss : [0.026047171226569583] Val Score : [0.7573184229436457])\n",
      "Epoch : [124] Train loss : [0.02717414764421327] Val Score : [0.7655703273293624])\n",
      "Epoch : [125] Train loss : [0.025485309905239513] Val Score : [0.7573184229436457])\n",
      "Epoch : [126] Train loss : [0.025367174563663348] Val Score : [0.762761970120889])\n",
      "Epoch : [127] Train loss : [0.026778225653937886] Val Score : [0.7600119366040216])\n",
      "Epoch : [128] Train loss : [0.027060102937476977] Val Score : [0.762761970120889])\n",
      "Epoch 00129: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch : [129] Train loss : [0.0243047797786338] Val Score : [0.762761970120889])\n",
      "Epoch : [130] Train loss : [0.022641309403947422] Val Score : [0.7600119366040216])\n",
      "Epoch : [131] Train loss : [0.02390440899346556] Val Score : [0.762761970120889])\n",
      "Epoch : [132] Train loss : [0.0231976682054145] Val Score : [0.7600119366040216])\n",
      "Epoch : [133] Train loss : [0.023420129237430438] Val Score : [0.7655703273293624])\n",
      "Epoch : [134] Train loss : [0.024013174697756767] Val Score : [0.762761970120889])\n",
      "Epoch : [135] Train loss : [0.02439297709081854] Val Score : [0.762761970120889])\n",
      "Epoch : [136] Train loss : [0.02336657339973109] Val Score : [0.762761970120889])\n",
      "Epoch : [137] Train loss : [0.023742076275604113] Val Score : [0.762761970120889])\n",
      "Epoch : [138] Train loss : [0.023563057716403688] Val Score : [0.762761970120889])\n",
      "Epoch : [139] Train loss : [0.023150368194494928] Val Score : [0.762761970120889])\n",
      "Epoch 00140: reducing learning rate of group 0 to 6.2500e-04.\n",
      "Epoch : [140] Train loss : [0.021549729896443232] Val Score : [0.762761970120889])\n",
      "Epoch : [141] Train loss : [0.020315722163234438] Val Score : [0.762761970120889])\n",
      "Epoch : [142] Train loss : [0.021573710654463087] Val Score : [0.762761970120889])\n",
      "Epoch : [143] Train loss : [0.0216304071779762] Val Score : [0.762761970120889])\n",
      "Epoch : [144] Train loss : [0.021326501188533648] Val Score : [0.762761970120889])\n",
      "Epoch : [145] Train loss : [0.022706620129091398] Val Score : [0.762761970120889])\n",
      "Epoch : [146] Train loss : [0.021202950339232172] Val Score : [0.762761970120889])\n",
      "Epoch : [147] Train loss : [0.021025212481617928] Val Score : [0.762761970120889])\n",
      "Epoch : [148] Train loss : [0.021515301295689175] Val Score : [0.762761970120889])\n",
      "Epoch : [149] Train loss : [0.02145727484353951] Val Score : [0.762761970120889])\n",
      "Epoch : [150] Train loss : [0.023205139009015902] Val Score : [0.762761970120889])\n",
      "Epoch 00151: reducing learning rate of group 0 to 3.1250e-04.\n",
      "Epoch : [151] Train loss : [0.020981579752905027] Val Score : [0.762761970120889])\n",
      "Epoch : [152] Train loss : [0.02007379329630307] Val Score : [0.762761970120889])\n",
      "Epoch : [153] Train loss : [0.019870308893067495] Val Score : [0.762761970120889])\n",
      "Epoch : [154] Train loss : [0.02096014070723738] Val Score : [0.762761970120889])\n",
      "Epoch : [155] Train loss : [0.020231154348169054] Val Score : [0.762761970120889])\n",
      "Epoch : [156] Train loss : [0.020075103800211633] Val Score : [0.762761970120889])\n",
      "Epoch : [157] Train loss : [0.020903647478137697] Val Score : [0.762761970120889])\n",
      "Epoch : [158] Train loss : [0.01897291573030608] Val Score : [0.762761970120889])\n",
      "Epoch : [159] Train loss : [0.020230578258633614] Val Score : [0.762761970120889])\n",
      "Epoch : [160] Train loss : [0.02090387312429292] Val Score : [0.762761970120889])\n",
      "Epoch : [161] Train loss : [0.0198639522173575] Val Score : [0.762761970120889])\n",
      "Epoch 00162: reducing learning rate of group 0 to 1.5625e-04.\n",
      "Epoch : [162] Train loss : [0.020340433344244957] Val Score : [0.762761970120889])\n",
      "Epoch : [163] Train loss : [0.02021162211894989] Val Score : [0.762761970120889])\n",
      "Epoch : [164] Train loss : [0.02138467026608331] Val Score : [0.762761970120889])\n",
      "Epoch : [165] Train loss : [0.019671167113951275] Val Score : [0.762761970120889])\n",
      "Epoch : [166] Train loss : [0.020451110654643605] Val Score : [0.762761970120889])\n",
      "Epoch : [167] Train loss : [0.019249715975352695] Val Score : [0.762761970120889])\n",
      "Epoch : [168] Train loss : [0.020048958648528372] Val Score : [0.762761970120889])\n",
      "Epoch : [169] Train loss : [0.019496459513902664] Val Score : [0.762761970120889])\n",
      "Epoch : [170] Train loss : [0.018857238814234734] Val Score : [0.762761970120889])\n",
      "Epoch : [171] Train loss : [0.018975394644907544] Val Score : [0.762761970120889])\n",
      "Epoch : [172] Train loss : [0.02019265027982848] Val Score : [0.762761970120889])\n",
      "Epoch 00173: reducing learning rate of group 0 to 7.8125e-05.\n",
      "Epoch : [173] Train loss : [0.02048915464963232] Val Score : [0.762761970120889])\n",
      "Epoch : [174] Train loss : [0.02057932609958308] Val Score : [0.762761970120889])\n",
      "Epoch : [175] Train loss : [0.019604965512241636] Val Score : [0.762761970120889])\n",
      "Epoch : [176] Train loss : [0.018991188279220035] Val Score : [0.762761970120889])\n",
      "Epoch : [177] Train loss : [0.021003832508410727] Val Score : [0.762761970120889])\n",
      "Epoch : [178] Train loss : [0.02056208997964859] Val Score : [0.762761970120889])\n",
      "Epoch : [179] Train loss : [0.020261752818311964] Val Score : [0.762761970120889])\n",
      "Epoch : [180] Train loss : [0.019845913031271527] Val Score : [0.762761970120889])\n",
      "Epoch : [181] Train loss : [0.019540238327213695] Val Score : [0.762761970120889])\n",
      "Epoch : [182] Train loss : [0.020467253401875496] Val Score : [0.762761970120889])\n",
      "Epoch : [183] Train loss : [0.01917878458542483] Val Score : [0.762761970120889])\n",
      "Epoch 00184: reducing learning rate of group 0 to 3.9063e-05.\n",
      "Epoch : [184] Train loss : [0.02124603385371821] Val Score : [0.762761970120889])\n",
      "Epoch : [185] Train loss : [0.021456686247672354] Val Score : [0.762761970120889])\n",
      "Epoch : [186] Train loss : [0.01951908346797739] Val Score : [0.762761970120889])\n",
      "Epoch : [187] Train loss : [0.019908016281468526] Val Score : [0.762761970120889])\n",
      "Epoch : [188] Train loss : [0.019930426829627583] Val Score : [0.762761970120889])\n",
      "Epoch : [189] Train loss : [0.01938124666256564] Val Score : [0.762761970120889])\n",
      "Epoch : [190] Train loss : [0.020392482302018573] Val Score : [0.762761970120889])\n",
      "Epoch : [191] Train loss : [0.01948604785970279] Val Score : [0.762761970120889])\n",
      "Epoch : [192] Train loss : [0.021513557859829495] Val Score : [0.762761970120889])\n",
      "Epoch : [193] Train loss : [0.020565197137849673] Val Score : [0.762761970120889])\n",
      "Epoch : [194] Train loss : [0.020441966131329536] Val Score : [0.762761970120889])\n",
      "Epoch 00195: reducing learning rate of group 0 to 1.9531e-05.\n",
      "Epoch : [195] Train loss : [0.020451583500419344] Val Score : [0.762761970120889])\n",
      "Epoch : [196] Train loss : [0.019351833100829805] Val Score : [0.762761970120889])\n",
      "Epoch : [197] Train loss : [0.01957615597971848] Val Score : [0.762761970120889])\n",
      "Epoch : [198] Train loss : [0.019412780978849957] Val Score : [0.762761970120889])\n",
      "Epoch : [199] Train loss : [0.02092100546828338] Val Score : [0.762761970120889])\n",
      "Epoch : [200] Train loss : [0.019580294777240072] Val Score : [0.762761970120889])\n",
      "Epoch : [201] Train loss : [0.01980236784688064] Val Score : [0.762761970120889])\n",
      "Epoch : [202] Train loss : [0.020415506990892545] Val Score : [0.762761970120889])\n",
      "Epoch : [203] Train loss : [0.01914482457297189] Val Score : [0.762761970120889])\n",
      "Epoch : [204] Train loss : [0.02011930596615587] Val Score : [0.762761970120889])\n",
      "Epoch : [205] Train loss : [0.020456343357052122] Val Score : [0.762761970120889])\n",
      "Epoch 00206: reducing learning rate of group 0 to 9.7656e-06.\n",
      "Epoch : [206] Train loss : [0.019213549526674405] Val Score : [0.762761970120889])\n",
      "Epoch : [207] Train loss : [0.019373186997004917] Val Score : [0.762761970120889])\n",
      "Epoch : [208] Train loss : [0.018618895539215634] Val Score : [0.762761970120889])\n",
      "Epoch : [209] Train loss : [0.020957745611667633] Val Score : [0.762761970120889])\n",
      "Epoch : [210] Train loss : [0.0198075356228011] Val Score : [0.762761970120889])\n",
      "Epoch : [211] Train loss : [0.020024161519748822] Val Score : [0.762761970120889])\n",
      "Epoch : [212] Train loss : [0.020259365173322812] Val Score : [0.762761970120889])\n",
      "Epoch : [213] Train loss : [0.019661734146731242] Val Score : [0.762761970120889])\n",
      "Epoch : [214] Train loss : [0.02109923506421702] Val Score : [0.762761970120889])\n",
      "Epoch : [215] Train loss : [0.01940204096691949] Val Score : [0.762761970120889])\n",
      "Epoch : [216] Train loss : [0.019038061744400432] Val Score : [0.762761970120889])\n",
      "Epoch 00217: reducing learning rate of group 0 to 4.8828e-06.\n",
      "Epoch : [217] Train loss : [0.021059066323297366] Val Score : [0.762761970120889])\n",
      "Epoch : [218] Train loss : [0.019332891596215113] Val Score : [0.762761970120889])\n",
      "Epoch : [219] Train loss : [0.020695145641054426] Val Score : [0.762761970120889])\n",
      "Epoch : [220] Train loss : [0.018888362550309727] Val Score : [0.762761970120889])\n",
      "Epoch : [221] Train loss : [0.01855380700102874] Val Score : [0.762761970120889])\n",
      "Epoch : [222] Train loss : [0.020668701933962957] Val Score : [0.762761970120889])\n",
      "Epoch : [223] Train loss : [0.02062361261674336] Val Score : [0.762761970120889])\n",
      "Epoch : [224] Train loss : [0.020908639101045474] Val Score : [0.762761970120889])\n",
      "Epoch : [225] Train loss : [0.020106770364301547] Val Score : [0.762761970120889])\n",
      "Epoch : [226] Train loss : [0.020042778125831058] Val Score : [0.762761970120889])\n",
      "Epoch : [227] Train loss : [0.018663735261985233] Val Score : [0.762761970120889])\n",
      "Epoch 00228: reducing learning rate of group 0 to 2.4414e-06.\n",
      "Epoch : [228] Train loss : [0.01865361018904618] Val Score : [0.762761970120889])\n",
      "Epoch : [229] Train loss : [0.019351873812930926] Val Score : [0.762761970120889])\n",
      "Epoch : [230] Train loss : [0.020206056269151822] Val Score : [0.762761970120889])\n",
      "Epoch : [231] Train loss : [0.020076208082692965] Val Score : [0.762761970120889])\n",
      "Epoch : [232] Train loss : [0.020143355642046248] Val Score : [0.762761970120889])\n",
      "Epoch : [233] Train loss : [0.02053747033434255] Val Score : [0.762761970120889])\n",
      "Epoch : [234] Train loss : [0.019582756661943028] Val Score : [0.762761970120889])\n",
      "Epoch : [235] Train loss : [0.020663606269018992] Val Score : [0.762761970120889])\n",
      "Epoch : [236] Train loss : [0.020339582647596086] Val Score : [0.762761970120889])\n",
      "Epoch : [237] Train loss : [0.020424333534070423] Val Score : [0.762761970120889])\n",
      "Epoch : [238] Train loss : [0.019576156777994975] Val Score : [0.762761970120889])\n",
      "Epoch 00239: reducing learning rate of group 0 to 1.2207e-06.\n",
      "Epoch : [239] Train loss : [0.019314281376344816] Val Score : [0.762761970120889])\n",
      "Epoch : [240] Train loss : [0.020680510572024753] Val Score : [0.762761970120889])\n",
      "Epoch : [241] Train loss : [0.01933927328458854] Val Score : [0.762761970120889])\n",
      "Epoch : [242] Train loss : [0.019673345610499382] Val Score : [0.762761970120889])\n",
      "Epoch : [243] Train loss : [0.020372769396219934] Val Score : [0.762761970120889])\n",
      "Epoch : [244] Train loss : [0.020463787285344943] Val Score : [0.762761970120889])\n",
      "Epoch : [245] Train loss : [0.01871825541768755] Val Score : [0.762761970120889])\n",
      "Epoch : [246] Train loss : [0.01829339936375618] Val Score : [0.762761970120889])\n",
      "Epoch : [247] Train loss : [0.01969572209886142] Val Score : [0.762761970120889])\n",
      "Epoch : [248] Train loss : [0.019517092566405023] Val Score : [0.762761970120889])\n",
      "Epoch : [249] Train loss : [0.020116838227425302] Val Score : [0.762761970120889])\n",
      "Epoch 00250: reducing learning rate of group 0 to 6.1035e-07.\n",
      "Epoch : [250] Train loss : [0.01958004677934306] Val Score : [0.762761970120889])\n",
      "Epoch : [251] Train loss : [0.019582377480609075] Val Score : [0.762761970120889])\n",
      "Epoch : [252] Train loss : [0.02026524447969028] Val Score : [0.762761970120889])\n",
      "Epoch : [253] Train loss : [0.019416758524520055] Val Score : [0.762761970120889])\n",
      "Epoch : [254] Train loss : [0.01968108756201608] Val Score : [0.762761970120889])\n",
      "Epoch : [255] Train loss : [0.019033785643322126] Val Score : [0.762761970120889])\n",
      "Epoch : [256] Train loss : [0.02035960049501487] Val Score : [0.762761970120889])\n",
      "Epoch : [257] Train loss : [0.02020012347825936] Val Score : [0.762761970120889])\n",
      "Epoch : [258] Train loss : [0.020667006128600666] Val Score : [0.762761970120889])\n",
      "Epoch : [259] Train loss : [0.018783028902752057] Val Score : [0.762761970120889])\n",
      "Epoch : [260] Train loss : [0.019396702892013958] Val Score : [0.762761970120889])\n",
      "Epoch 00261: reducing learning rate of group 0 to 3.0518e-07.\n",
      "Epoch : [261] Train loss : [0.020855684365545] Val Score : [0.762761970120889])\n",
      "Epoch : [262] Train loss : [0.020539790658014163] Val Score : [0.762761970120889])\n",
      "Epoch : [263] Train loss : [0.020462941910539354] Val Score : [0.762761970120889])\n",
      "Epoch : [264] Train loss : [0.020936644236956323] Val Score : [0.762761970120889])\n",
      "Epoch : [265] Train loss : [0.01919845225555556] Val Score : [0.762761970120889])\n",
      "Epoch : [266] Train loss : [0.020503712285842215] Val Score : [0.762761970120889])\n",
      "Epoch : [267] Train loss : [0.020262442263109342] Val Score : [0.762761970120889])\n",
      "Epoch : [268] Train loss : [0.018788280497704233] Val Score : [0.762761970120889])\n",
      "Epoch : [269] Train loss : [0.01881875071142401] Val Score : [0.762761970120889])\n",
      "Epoch : [270] Train loss : [0.019638985661523684] Val Score : [0.762761970120889])\n",
      "Epoch : [271] Train loss : [0.020046535081097057] Val Score : [0.762761970120889])\n",
      "Epoch 00272: reducing learning rate of group 0 to 1.5259e-07.\n",
      "Epoch : [272] Train loss : [0.0206149337547166] Val Score : [0.762761970120889])\n",
      "Epoch : [273] Train loss : [0.020627191024167196] Val Score : [0.762761970120889])\n",
      "Epoch : [274] Train loss : [0.021528229915669987] Val Score : [0.762761970120889])\n",
      "Epoch : [275] Train loss : [0.020201727215732847] Val Score : [0.762761970120889])\n",
      "Epoch : [276] Train loss : [0.020858303510716984] Val Score : [0.762761970120889])\n",
      "Epoch : [277] Train loss : [0.02066985091992787] Val Score : [0.762761970120889])\n",
      "Epoch : [278] Train loss : [0.0204311412359987] Val Score : [0.762761970120889])\n",
      "Epoch : [279] Train loss : [0.01952927479786532] Val Score : [0.762761970120889])\n",
      "Epoch : [280] Train loss : [0.02075399591454438] Val Score : [0.762761970120889])\n",
      "Epoch : [281] Train loss : [0.01996010249214513] Val Score : [0.762761970120889])\n",
      "Epoch : [282] Train loss : [0.020317161455750465] Val Score : [0.762761970120889])\n",
      "Epoch 00283: reducing learning rate of group 0 to 7.6294e-08.\n",
      "Epoch : [283] Train loss : [0.01914991225515093] Val Score : [0.762761970120889])\n",
      "Epoch : [284] Train loss : [0.02006661013833114] Val Score : [0.762761970120889])\n",
      "Epoch : [285] Train loss : [0.019740465762359754] Val Score : [0.762761970120889])\n",
      "Epoch : [286] Train loss : [0.019156847947410176] Val Score : [0.762761970120889])\n",
      "Epoch : [287] Train loss : [0.020169160461851528] Val Score : [0.762761970120889])\n",
      "Epoch : [288] Train loss : [0.019731281059128896] Val Score : [0.762761970120889])\n",
      "Epoch : [289] Train loss : [0.018908396629350527] Val Score : [0.762761970120889])\n",
      "Epoch : [290] Train loss : [0.02005263843706676] Val Score : [0.762761970120889])\n",
      "Epoch : [291] Train loss : [0.019770947684134756] Val Score : [0.762761970120889])\n",
      "Epoch : [292] Train loss : [0.019139399752020836] Val Score : [0.762761970120889])\n",
      "Epoch : [293] Train loss : [0.02068373081939561] Val Score : [0.762761970120889])\n",
      "Epoch 00294: reducing learning rate of group 0 to 3.8147e-08.\n",
      "Epoch : [294] Train loss : [0.02058748049395425] Val Score : [0.762761970120889])\n",
      "Epoch : [295] Train loss : [0.01967521251312324] Val Score : [0.762761970120889])\n",
      "Epoch : [296] Train loss : [0.020370946930987493] Val Score : [0.762761970120889])\n",
      "Epoch : [297] Train loss : [0.018894221101488386] Val Score : [0.762761970120889])\n",
      "Epoch : [298] Train loss : [0.019969807405556952] Val Score : [0.762761970120889])\n",
      "Epoch : [299] Train loss : [0.0196037231279271] Val Score : [0.762761970120889])\n",
      "Epoch : [300] Train loss : [0.019296374704156603] Val Score : [0.762761970120889])\n",
      "Epoch : [301] Train loss : [0.019702709413000515] Val Score : [0.762761970120889])\n",
      "Epoch : [302] Train loss : [0.018767755744712695] Val Score : [0.762761970120889])\n",
      "Epoch : [303] Train loss : [0.020008000944341933] Val Score : [0.762761970120889])\n",
      "Epoch : [304] Train loss : [0.019108069262334278] Val Score : [0.762761970120889])\n",
      "Epoch 00305: reducing learning rate of group 0 to 1.9073e-08.\n",
      "Epoch : [305] Train loss : [0.018809696659445763] Val Score : [0.762761970120889])\n",
      "Epoch : [306] Train loss : [0.02021924432899271] Val Score : [0.762761970120889])\n",
      "Epoch : [307] Train loss : [0.022210027490343367] Val Score : [0.762761970120889])\n",
      "Epoch : [308] Train loss : [0.019619230713163103] Val Score : [0.762761970120889])\n",
      "Epoch : [309] Train loss : [0.02127765491604805] Val Score : [0.762761970120889])\n",
      "Epoch : [310] Train loss : [0.01963408317949091] Val Score : [0.762761970120889])\n",
      "Epoch : [311] Train loss : [0.0200104508548975] Val Score : [0.762761970120889])\n",
      "Epoch : [312] Train loss : [0.020972242312771932] Val Score : [0.762761970120889])\n",
      "Epoch : [313] Train loss : [0.019026990181633403] Val Score : [0.762761970120889])\n",
      "Epoch : [314] Train loss : [0.018975079591785158] Val Score : [0.762761970120889])\n",
      "Epoch : [315] Train loss : [0.020846866869500706] Val Score : [0.762761970120889])\n",
      "Epoch : [316] Train loss : [0.01987885178199836] Val Score : [0.762761970120889])\n",
      "Epoch : [317] Train loss : [0.022118946271283284] Val Score : [0.762761970120889])\n",
      "Epoch : [318] Train loss : [0.01785361873252051] Val Score : [0.762761970120889])\n",
      "Epoch : [319] Train loss : [0.01980035938322544] Val Score : [0.762761970120889])\n",
      "Epoch : [320] Train loss : [0.019853035254137858] Val Score : [0.762761970120889])\n",
      "Epoch : [321] Train loss : [0.0198605763060706] Val Score : [0.762761970120889])\n",
      "Epoch : [322] Train loss : [0.020789995523435727] Val Score : [0.762761970120889])\n",
      "Epoch : [323] Train loss : [0.02042811630027635] Val Score : [0.762761970120889])\n",
      "Epoch : [324] Train loss : [0.01993453023689134] Val Score : [0.762761970120889])\n",
      "Epoch : [325] Train loss : [0.020440983452967236] Val Score : [0.762761970120889])\n",
      "Epoch : [326] Train loss : [0.020360308566263745] Val Score : [0.762761970120889])\n",
      "Epoch : [327] Train loss : [0.02065935278577464] Val Score : [0.762761970120889])\n",
      "Epoch : [328] Train loss : [0.020190509568367685] Val Score : [0.762761970120889])\n",
      "Epoch : [329] Train loss : [0.020352879805224284] Val Score : [0.762761970120889])\n",
      "Epoch : [330] Train loss : [0.02001482487789222] Val Score : [0.762761970120889])\n",
      "Epoch : [331] Train loss : [0.019097375284348215] Val Score : [0.762761970120889])\n",
      "Epoch : [332] Train loss : [0.01914891228079796] Val Score : [0.762761970120889])\n",
      "Epoch : [333] Train loss : [0.02138244467122214] Val Score : [0.762761970120889])\n",
      "Epoch : [334] Train loss : [0.020081889416490282] Val Score : [0.762761970120889])\n",
      "Epoch : [335] Train loss : [0.020734203181096485] Val Score : [0.762761970120889])\n",
      "Epoch : [336] Train loss : [0.02015160716005734] Val Score : [0.762761970120889])\n",
      "Epoch : [337] Train loss : [0.019153445959091187] Val Score : [0.762761970120889])\n",
      "Epoch : [338] Train loss : [0.01972976672862257] Val Score : [0.762761970120889])\n",
      "Epoch : [339] Train loss : [0.021605893703443662] Val Score : [0.762761970120889])\n",
      "Epoch : [340] Train loss : [0.02021353638597897] Val Score : [0.762761970120889])\n",
      "Epoch : [341] Train loss : [0.02000123555106776] Val Score : [0.762761970120889])\n",
      "Epoch : [342] Train loss : [0.020647270338875905] Val Score : [0.762761970120889])\n",
      "Epoch : [343] Train loss : [0.020283328635352] Val Score : [0.762761970120889])\n",
      "Epoch : [344] Train loss : [0.0184544532426766] Val Score : [0.762761970120889])\n",
      "Epoch : [345] Train loss : [0.01917348030422415] Val Score : [0.762761970120889])\n",
      "Epoch : [346] Train loss : [0.019821822377187864] Val Score : [0.762761970120889])\n",
      "Epoch : [347] Train loss : [0.020639847165771892] Val Score : [0.762761970120889])\n",
      "Epoch : [348] Train loss : [0.01968698443046638] Val Score : [0.762761970120889])\n",
      "Epoch : [349] Train loss : [0.018791910527007922] Val Score : [0.762761970120889])\n",
      "Epoch : [350] Train loss : [0.021167019116027013] Val Score : [0.762761970120889])\n",
      "Epoch : [351] Train loss : [0.02118437151823725] Val Score : [0.762761970120889])\n",
      "Epoch : [352] Train loss : [0.020513547584414482] Val Score : [0.762761970120889])\n",
      "Epoch : [353] Train loss : [0.021226251231772558] Val Score : [0.762761970120889])\n",
      "Epoch : [354] Train loss : [0.01887666274394308] Val Score : [0.762761970120889])\n",
      "Epoch : [355] Train loss : [0.01962805033794471] Val Score : [0.762761970120889])\n",
      "Epoch : [356] Train loss : [0.019706578659159795] Val Score : [0.762761970120889])\n",
      "Epoch : [357] Train loss : [0.020575048934136118] Val Score : [0.762761970120889])\n",
      "Epoch : [358] Train loss : [0.02048864827624389] Val Score : [0.762761970120889])\n",
      "Epoch : [359] Train loss : [0.020615713138665472] Val Score : [0.762761970120889])\n",
      "Epoch : [360] Train loss : [0.019555477691548213] Val Score : [0.762761970120889])\n",
      "Epoch : [361] Train loss : [0.019580110109278133] Val Score : [0.762761970120889])\n",
      "Epoch : [362] Train loss : [0.02048067588891302] Val Score : [0.762761970120889])\n",
      "Epoch : [363] Train loss : [0.01965624200446265] Val Score : [0.762761970120889])\n",
      "Epoch : [364] Train loss : [0.020804223471454213] Val Score : [0.762761970120889])\n",
      "Epoch : [365] Train loss : [0.01942381608699049] Val Score : [0.762761970120889])\n",
      "Epoch : [366] Train loss : [0.0194083500121321] Val Score : [0.762761970120889])\n",
      "Epoch : [367] Train loss : [0.019794394927365438] Val Score : [0.762761970120889])\n",
      "Epoch : [368] Train loss : [0.019730806882892336] Val Score : [0.762761970120889])\n",
      "Epoch : [369] Train loss : [0.02038671901183469] Val Score : [0.762761970120889])\n",
      "Epoch : [370] Train loss : [0.02009949354188783] Val Score : [0.762761970120889])\n",
      "Epoch : [371] Train loss : [0.020123268344572613] Val Score : [0.762761970120889])\n",
      "Epoch : [372] Train loss : [0.019226415614996637] Val Score : [0.762761970120889])\n",
      "Epoch : [373] Train loss : [0.020324126950332096] Val Score : [0.762761970120889])\n",
      "Epoch : [374] Train loss : [0.01946300534265382] Val Score : [0.762761970120889])\n",
      "Epoch : [375] Train loss : [0.020563211824212755] Val Score : [0.762761970120889])\n",
      "Epoch : [376] Train loss : [0.020469402628285543] Val Score : [0.762761970120889])\n",
      "Epoch : [377] Train loss : [0.018755080444472178] Val Score : [0.762761970120889])\n",
      "Epoch : [378] Train loss : [0.02022178071950163] Val Score : [0.762761970120889])\n",
      "Epoch : [379] Train loss : [0.020400891612683023] Val Score : [0.762761970120889])\n",
      "Epoch : [380] Train loss : [0.019466398283839226] Val Score : [0.762761970120889])\n",
      "Epoch : [381] Train loss : [0.019210425072482655] Val Score : [0.762761970120889])\n",
      "Epoch : [382] Train loss : [0.020308425650000572] Val Score : [0.762761970120889])\n",
      "Epoch : [383] Train loss : [0.019780768613730158] Val Score : [0.762761970120889])\n",
      "Epoch : [384] Train loss : [0.019693243450352123] Val Score : [0.762761970120889])\n",
      "Epoch : [385] Train loss : [0.019510090883289064] Val Score : [0.762761970120889])\n",
      "Epoch : [386] Train loss : [0.019117669335433414] Val Score : [0.762761970120889])\n",
      "Epoch : [387] Train loss : [0.019245128812534467] Val Score : [0.762761970120889])\n",
      "Epoch : [388] Train loss : [0.019937538408807347] Val Score : [0.762761970120889])\n",
      "Epoch : [389] Train loss : [0.020225060305425098] Val Score : [0.762761970120889])\n",
      "Epoch : [390] Train loss : [0.01972996204027108] Val Score : [0.762761970120889])\n",
      "Epoch : [391] Train loss : [0.020179397825683867] Val Score : [0.762761970120889])\n",
      "Epoch : [392] Train loss : [0.019668427162936757] Val Score : [0.762761970120889])\n",
      "Epoch : [393] Train loss : [0.020221218732850894] Val Score : [0.762761970120889])\n",
      "Epoch : [394] Train loss : [0.019960250173296248] Val Score : [0.762761970120889])\n",
      "Epoch : [395] Train loss : [0.019942089915275574] Val Score : [0.762761970120889])\n",
      "Epoch : [396] Train loss : [0.019230058948908533] Val Score : [0.762761970120889])\n",
      "Epoch : [397] Train loss : [0.02056616491505078] Val Score : [0.762761970120889])\n",
      "Epoch : [398] Train loss : [0.021649629143731936] Val Score : [0.762761970120889])\n",
      "Epoch : [399] Train loss : [0.020152362595711435] Val Score : [0.762761970120889])\n"
     ]
    }
   ],
   "source": [
    "model = nn.DataParallel(AutoEncoder())\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee1a4c-afe9-4f3c-a3f6-3bca5eb2109f",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c53e6313-382b-4f31-a587-1824c579abb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AutoEncoder(\n",
       "    (Encoder): Sequential(\n",
       "      (0): Linear(in_features=30, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (Decoder): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Linear(in_features=64, out_features=30, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoEncoder()\n",
    "model.load_state_dict(torch.load('./best_model.pth'))\n",
    "model = nn.DataParallel(model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65628d5a-dedd-4525-8f9d-ba3f00de9eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test.csv')\n",
    "test_df = test_df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e87c859b-be5a-426b-8a02-08ff5b38f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataset(test_df, False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82bb801c-9207-4e2d-a44e-1b86eab8ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, thr, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for x in iter(test_loader):\n",
    "            x = x.float().to(device)\n",
    "            \n",
    "            _x = model(x)\n",
    "            \n",
    "            diff = cos(x, _x).cpu().tolist()\n",
    "            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
    "            pred += batch_pred\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d85fcc2-a3a7-451c-878f-8a0bb105c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = prediction(model, 0.95, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ff9df77-6591-441d-a4ce-1a0aacc8f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit['Class'] = preds\n",
    "submit.to_csv('./elipt_auto.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('for_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d5361de2d3a86ff8022af11ead2fa25aee948dfb14ed55cb3d2da795443f4cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
